{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5856632-0e2c-4115-a8b2-0c62c22c6115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.72\n",
      "\n",
      "Mismatched Entries:\n",
      "{'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'disease_progression_after_previous_treatment', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'anc_level_lower_bound_10_9_l', 'ground_truth': 3, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'demographics_and_general_characteristics', 'key': 'months_of_life_expectancy', 'ground_truth': 4, 'gpt_extracted': 3, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Negative only', 'gpt_extracted': 'Both allowed', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'er_pr_status', 'ground_truth': 'Negative only', 'gpt_extracted': 'Both allowed', 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'sufficient_lung_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 3, 'gpt_extracted': 2, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'hgb_level_lower_bound_10_9_l', 'ground_truth': 9, 'gpt_extracted': 8.5, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 60, 'gpt_extracted': 51, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 1, 'gpt_extracted': 2, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 1, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'demographics_and_general_characteristics', 'key': 'months_of_life_expectancy', 'ground_truth': 3, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Both allowed', 'gpt_extracted': 'Negative only', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'er_pr_status', 'ground_truth': 'Both allowed', 'gpt_extracted': 'Negative only', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'measurable_lesion', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_ast_alt_upper_bound_uln', 'ground_truth': 5, 'gpt_extracted': 2.5, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': 1.5, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 51, 'gpt_extracted': 40, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'hgb_level_lower_bound_10_9_l', 'ground_truth': 8.5, 'gpt_extracted': 9, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 2, 'gpt_extracted': 1, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 1, 'gpt_extracted': 2, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'positive_hiv_status', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'creatinine_upper_bound_uln', 'ground_truth': 1.5, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 40, 'gpt_extracted': 60, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 1, 'gpt_extracted': 2, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Negative only', 'gpt_extracted': 'Positive only', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'er_pr_status', 'ground_truth': 'Negative only', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'measurable_lesion', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'sufficient_lung_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_ast_alt_upper_bound_uln', 'ground_truth': 2.5, 'gpt_extracted': 5, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 1.5, 'gpt_extracted': 2, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'plt_level_lower_bound_10_9_l', 'ground_truth': 100, 'gpt_extracted': 75, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 2, 'gpt_extracted': 1, 'match': False}\n",
      "{'section': 'demographics_and_general_characteristics', 'key': 'no_participation_in_other_clinical_trials', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Positive only', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'sufficient_renal_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_ast_alt_upper_bound_uln', 'ground_truth': 5, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'lvef_lower_bound_percent', 'ground_truth': 50, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'anc_level_lower_bound_10_9_l', 'ground_truth': 1.5, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'creatinine_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 50, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'hgb_level_lower_bound_10_9_l', 'ground_truth': 9, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'plt_level_lower_bound_10_9_l', 'ground_truth': 75, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'karnofsky_performance_lower_bound', 'ground_truth': 70, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 1, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'disease_progression_after_previous_treatment', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 1, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'positive_hiv_status', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'demographics_and_general_characteristics', 'key': 'no_participation_in_other_clinical_trials', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Negative only', 'gpt_extracted': 'Positive only', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'er_pr_status', 'ground_truth': 'Negative only', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_ast_alt_upper_bound_uln', 'ground_truth': 5, 'gpt_extracted': 1, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': 1, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'anc_level_lower_bound_10_9_l', 'ground_truth': 1.5, 'gpt_extracted': 0, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'creatinine_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': 1, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'hgb_level_lower_bound_10_9_l', 'ground_truth': 10, 'gpt_extracted': 0, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'plt_level_lower_bound_10_9_l', 'ground_truth': 100, 'gpt_extracted': 0, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'karnofsky_performance_lower_bound', 'ground_truth': 70, 'gpt_extracted': 0, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 0, 'gpt_extracted': 1, 'match': False}\n",
      "{'section': 'demographics_and_general_characteristics', 'key': 'months_of_life_expectancy', 'ground_truth': 3, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Positive only', 'gpt_extracted': 'Negative only', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'measurable_lesion', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'sufficient_bone_marrow', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'sufficient_liver_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'sufficient_heart_cardiovascular_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'sufficient_renal_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'lvef_lower_bound_percent', 'ground_truth': 50, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 1, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'positive_hiv_status', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'confirmed_breast_cancer', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Negative only', 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'measurable_lesion', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'lvef_lower_bound_percent', 'ground_truth': 50, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'demographics_and_general_characteristics', 'key': 'months_of_life_expectancy', 'ground_truth': 3, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'demographics_and_general_characteristics', 'key': 'no_participation_in_other_clinical_trials', 'ground_truth': 'Required', 'gpt_extracted': 'Not required', 'match': False}\n",
      "{'section': 'disease_characteristics', 'key': 'confirmed_breast_cancer', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'sufficient_heart_cardiovascular_function', 'ground_truth': 'Required', 'gpt_extracted': 'Not required', 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 3, 'gpt_extracted': 1.5, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 2, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 60, 'gpt_extracted': None, 'match': False}\n",
      "{'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "\n",
      "Mismatch Count by Section and Key:\n",
      "Section: health_and_organ_function\n",
      "  untreated_central_nervous_system_metastases: 8 mismatches\n",
      "  anc_level_lower_bound_10_9_l: 3 mismatches\n",
      "  sufficient_lung_function: 2 mismatches\n",
      "  liver_function_bilirubin_upper_bound_uln: 6 mismatches\n",
      "  hgb_level_lower_bound_10_9_l: 4 mismatches\n",
      "  creatinine_clearance_lower_bound: 5 mismatches\n",
      "  ecog_performance_status_upper_bound: 5 mismatches\n",
      "  peripheral_neuropathy_grade_upper_bound: 6 mismatches\n",
      "  liver_function_ast_alt_upper_bound_uln: 4 mismatches\n",
      "  positive_hiv_status: 3 mismatches\n",
      "  creatinine_upper_bound_uln: 3 mismatches\n",
      "  plt_level_lower_bound_10_9_l: 3 mismatches\n",
      "  sufficient_renal_function: 2 mismatches\n",
      "  lvef_lower_bound_percent: 3 mismatches\n",
      "  karnofsky_performance_lower_bound: 2 mismatches\n",
      "  sufficient_bone_marrow: 1 mismatches\n",
      "  sufficient_liver_function: 1 mismatches\n",
      "  sufficient_heart_cardiovascular_function: 2 mismatches\n",
      "Section: disease_characteristics\n",
      "  disease_progression_after_previous_treatment: 2 mismatches\n",
      "  her2_status: 7 mismatches\n",
      "  er_pr_status: 4 mismatches\n",
      "  measurable_lesion: 4 mismatches\n",
      "  confirmed_metastases_breast_cancer: 6 mismatches\n",
      "  confirmed_breast_cancer: 2 mismatches\n",
      "Section: demographics_and_general_characteristics\n",
      "  months_of_life_expectancy: 4 mismatches\n",
      "  no_participation_in_other_clinical_trials: 3 mismatches\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def compare_extracted_criteria(gpt_data, ground_truth_data):\n",
    "    results = []\n",
    "    mismatch_counts = defaultdict(lambda: defaultdict(int))  # Track mismatches by section and key\n",
    "\n",
    "    for gpt_trial, gt_trial in zip(gpt_data, ground_truth_data):\n",
    "        gpt_criteria = gpt_trial.get(\"Extracted Criteria\", {})\n",
    "        gt_criteria = gt_trial.get(\"Extracted Criteria\", {})\n",
    "\n",
    "        for section in gpt_criteria:\n",
    "            # Skip specific sections\n",
    "            if section in [\"text_relating_to_medical_history\", \"unused_text\"]:\n",
    "                continue\n",
    "\n",
    "            gpt_section = gpt_criteria.get(section, {})\n",
    "            gt_section = gt_criteria.get(section, {})\n",
    "\n",
    "            for key, gt_value in gt_section.items():\n",
    "                gpt_value = gpt_section.get(key, None)\n",
    "                if (gpt_value in [\"Not required\", \"Both allowed\",\"Allowed\",0] and not gt_value) or \\\n",
    "                   (gt_value in [\"Not required\", \"Both allowed\", \"Allowed\",0] and not gpt_value):\n",
    "                    match = True\n",
    "                else:\n",
    "                    match = gt_value == gpt_value\n",
    "\n",
    "\n",
    "                results.append({\n",
    "                    \"section\": section,\n",
    "                    \"key\": key,\n",
    "                    \"ground_truth\": gt_value,\n",
    "                    \"gpt_extracted\": gpt_value,\n",
    "                    \"match\": match\n",
    "                })\n",
    "\n",
    "                # Increment mismatch count for the key in the section if there's a mismatch\n",
    "                if not match:\n",
    "                    mismatch_counts[section][key] += 1\n",
    "\n",
    "    return results, mismatch_counts\n",
    "\n",
    "\n",
    "def calculate_accuracy(results):\n",
    "    total = len(results)\n",
    "    matches = sum(1 for result in results if result[\"match\"])\n",
    "    return matches / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    gpt_file = \"extracted_criteria_30_new_merged.json\"\n",
    "    ground_truth_file = \"ground_truth_30.json\"\n",
    "\n",
    "    # Load data\n",
    "    gpt_data = load_json(gpt_file)\n",
    "    ground_truth_data = load_json(ground_truth_file)\n",
    "\n",
    "    # Compare criteria\n",
    "    comparison_results, mismatch_counts = compare_extracted_criteria(gpt_data, ground_truth_data)\n",
    "\n",
    "    accuracy = calculate_accuracy(comparison_results)\n",
    "    print(f\"Overall Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    mismatches = [r for r in comparison_results if not r[\"match\"]]\n",
    "    if mismatches:\n",
    "        print(\"\\nMismatched Entries:\")\n",
    "        for mismatch in mismatches:\n",
    "            print(mismatch)\n",
    "\n",
    "    print(\"\\nMismatch Count by Section and Key:\")\n",
    "    for section, keys in mismatch_counts.items():\n",
    "        print(f\"Section: {section}\")\n",
    "        for key, count in keys.items():\n",
    "            print(f\"  {key}: {count} mismatches\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06bf6189-8584-4b30-b213-12c16c778304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.72\n",
      "\n",
      "Mismatched Entries:\n",
      "Trial 5: {'trial_number': 5, 'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "Trial 9: {'trial_number': 9, 'section': 'disease_characteristics', 'key': 'disease_progression_after_previous_treatment', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 9: {'trial_number': 9, 'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "Trial 10: {'trial_number': 10, 'section': 'health_and_organ_function', 'key': 'anc_level_lower_bound_10_9_l', 'ground_truth': 3, 'gpt_extracted': None, 'match': False}\n",
      "Trial 10: {'trial_number': 10, 'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'demographics_and_general_characteristics', 'key': 'months_of_life_expectancy', 'ground_truth': 4, 'gpt_extracted': 3, 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Negative only', 'gpt_extracted': 'Both allowed', 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'disease_characteristics', 'key': 'er_pr_status', 'ground_truth': 'Negative only', 'gpt_extracted': 'Both allowed', 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'health_and_organ_function', 'key': 'sufficient_lung_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 3, 'gpt_extracted': 2, 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'health_and_organ_function', 'key': 'hgb_level_lower_bound_10_9_l', 'ground_truth': 9, 'gpt_extracted': 8.5, 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 60, 'gpt_extracted': 51, 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 1, 'gpt_extracted': 2, 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "Trial 13: {'trial_number': 13, 'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 1, 'gpt_extracted': None, 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'demographics_and_general_characteristics', 'key': 'months_of_life_expectancy', 'ground_truth': 3, 'gpt_extracted': None, 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Both allowed', 'gpt_extracted': 'Negative only', 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'disease_characteristics', 'key': 'er_pr_status', 'ground_truth': 'Both allowed', 'gpt_extracted': 'Negative only', 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'disease_characteristics', 'key': 'measurable_lesion', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'health_and_organ_function', 'key': 'liver_function_ast_alt_upper_bound_uln', 'ground_truth': 5, 'gpt_extracted': 2.5, 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': 1.5, 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 51, 'gpt_extracted': 40, 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'health_and_organ_function', 'key': 'hgb_level_lower_bound_10_9_l', 'ground_truth': 8.5, 'gpt_extracted': 9, 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 2, 'gpt_extracted': 1, 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 1, 'gpt_extracted': 2, 'match': False}\n",
      "Trial 14: {'trial_number': 14, 'section': 'health_and_organ_function', 'key': 'positive_hiv_status', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "Trial 15: {'trial_number': 15, 'section': 'health_and_organ_function', 'key': 'creatinine_upper_bound_uln', 'ground_truth': 1.5, 'gpt_extracted': None, 'match': False}\n",
      "Trial 15: {'trial_number': 15, 'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 40, 'gpt_extracted': 60, 'match': False}\n",
      "Trial 15: {'trial_number': 15, 'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 1, 'gpt_extracted': 2, 'match': False}\n",
      "Trial 15: {'trial_number': 15, 'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "Trial 16: {'trial_number': 16, 'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "Trial 16: {'trial_number': 16, 'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Negative only', 'gpt_extracted': 'Positive only', 'match': False}\n",
      "Trial 16: {'trial_number': 16, 'section': 'disease_characteristics', 'key': 'er_pr_status', 'ground_truth': 'Negative only', 'gpt_extracted': None, 'match': False}\n",
      "Trial 16: {'trial_number': 16, 'section': 'disease_characteristics', 'key': 'measurable_lesion', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "Trial 16: {'trial_number': 16, 'section': 'health_and_organ_function', 'key': 'sufficient_lung_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 16: {'trial_number': 16, 'section': 'health_and_organ_function', 'key': 'liver_function_ast_alt_upper_bound_uln', 'ground_truth': 2.5, 'gpt_extracted': 5, 'match': False}\n",
      "Trial 16: {'trial_number': 16, 'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 1.5, 'gpt_extracted': 2, 'match': False}\n",
      "Trial 16: {'trial_number': 16, 'section': 'health_and_organ_function', 'key': 'plt_level_lower_bound_10_9_l', 'ground_truth': 100, 'gpt_extracted': 75, 'match': False}\n",
      "Trial 16: {'trial_number': 16, 'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 2, 'gpt_extracted': 1, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'demographics_and_general_characteristics', 'key': 'no_participation_in_other_clinical_trials', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Positive only', 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'sufficient_renal_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'liver_function_ast_alt_upper_bound_uln', 'ground_truth': 5, 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'lvef_lower_bound_percent', 'ground_truth': 50, 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'anc_level_lower_bound_10_9_l', 'ground_truth': 1.5, 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'creatinine_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 50, 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'hgb_level_lower_bound_10_9_l', 'ground_truth': 9, 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'plt_level_lower_bound_10_9_l', 'ground_truth': 75, 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'karnofsky_performance_lower_bound', 'ground_truth': 70, 'gpt_extracted': None, 'match': False}\n",
      "Trial 17: {'trial_number': 17, 'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 1, 'gpt_extracted': None, 'match': False}\n",
      "Trial 18: {'trial_number': 18, 'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "Trial 18: {'trial_number': 18, 'section': 'disease_characteristics', 'key': 'disease_progression_after_previous_treatment', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 18: {'trial_number': 18, 'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 1, 'gpt_extracted': None, 'match': False}\n",
      "Trial 18: {'trial_number': 18, 'section': 'health_and_organ_function', 'key': 'positive_hiv_status', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'demographics_and_general_characteristics', 'key': 'no_participation_in_other_clinical_trials', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Negative only', 'gpt_extracted': 'Positive only', 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'disease_characteristics', 'key': 'er_pr_status', 'ground_truth': 'Negative only', 'gpt_extracted': None, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'health_and_organ_function', 'key': 'liver_function_ast_alt_upper_bound_uln', 'ground_truth': 5, 'gpt_extracted': 1, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': 1, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'health_and_organ_function', 'key': 'anc_level_lower_bound_10_9_l', 'ground_truth': 1.5, 'gpt_extracted': 0, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'health_and_organ_function', 'key': 'creatinine_upper_bound_uln', 'ground_truth': 2, 'gpt_extracted': 1, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'health_and_organ_function', 'key': 'hgb_level_lower_bound_10_9_l', 'ground_truth': 10, 'gpt_extracted': 0, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'health_and_organ_function', 'key': 'plt_level_lower_bound_10_9_l', 'ground_truth': 100, 'gpt_extracted': 0, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'health_and_organ_function', 'key': 'karnofsky_performance_lower_bound', 'ground_truth': 70, 'gpt_extracted': 0, 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "Trial 19: {'trial_number': 19, 'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 0, 'gpt_extracted': 1, 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'demographics_and_general_characteristics', 'key': 'months_of_life_expectancy', 'ground_truth': 3, 'gpt_extracted': None, 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Positive only', 'gpt_extracted': 'Negative only', 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'disease_characteristics', 'key': 'measurable_lesion', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'health_and_organ_function', 'key': 'sufficient_bone_marrow', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'health_and_organ_function', 'key': 'sufficient_liver_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'health_and_organ_function', 'key': 'sufficient_heart_cardiovascular_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'health_and_organ_function', 'key': 'sufficient_renal_function', 'ground_truth': 'Required', 'gpt_extracted': None, 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'health_and_organ_function', 'key': 'lvef_lower_bound_percent', 'ground_truth': 50, 'gpt_extracted': None, 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'health_and_organ_function', 'key': 'peripheral_neuropathy_grade_upper_bound', 'ground_truth': 1, 'gpt_extracted': None, 'match': False}\n",
      "Trial 20: {'trial_number': 20, 'section': 'health_and_organ_function', 'key': 'positive_hiv_status', 'ground_truth': 'Not allowed', 'gpt_extracted': None, 'match': False}\n",
      "Trial 21: {'trial_number': 21, 'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "Trial 22: {'trial_number': 22, 'section': 'disease_characteristics', 'key': 'confirmed_breast_cancer', 'ground_truth': 'Required', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "Trial 22: {'trial_number': 22, 'section': 'disease_characteristics', 'key': 'confirmed_metastases_breast_cancer', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "Trial 22: {'trial_number': 22, 'section': 'disease_characteristics', 'key': 'her2_status', 'ground_truth': 'Negative only', 'gpt_extracted': None, 'match': False}\n",
      "Trial 22: {'trial_number': 22, 'section': 'disease_characteristics', 'key': 'measurable_lesion', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "Trial 22: {'trial_number': 22, 'section': 'health_and_organ_function', 'key': 'lvef_lower_bound_percent', 'ground_truth': 50, 'gpt_extracted': None, 'match': False}\n",
      "Trial 23: {'trial_number': 23, 'section': 'demographics_and_general_characteristics', 'key': 'months_of_life_expectancy', 'ground_truth': 3, 'gpt_extracted': None, 'match': False}\n",
      "Trial 23: {'trial_number': 23, 'section': 'demographics_and_general_characteristics', 'key': 'no_participation_in_other_clinical_trials', 'ground_truth': 'Required', 'gpt_extracted': 'Not required', 'match': False}\n",
      "Trial 23: {'trial_number': 23, 'section': 'disease_characteristics', 'key': 'confirmed_breast_cancer', 'ground_truth': 'Allowed', 'gpt_extracted': 'Required', 'match': False}\n",
      "Trial 23: {'trial_number': 23, 'section': 'health_and_organ_function', 'key': 'sufficient_heart_cardiovascular_function', 'ground_truth': 'Required', 'gpt_extracted': 'Not required', 'match': False}\n",
      "Trial 23: {'trial_number': 23, 'section': 'health_and_organ_function', 'key': 'liver_function_bilirubin_upper_bound_uln', 'ground_truth': 3, 'gpt_extracted': 1.5, 'match': False}\n",
      "Trial 23: {'trial_number': 23, 'section': 'health_and_organ_function', 'key': 'ecog_performance_status_upper_bound', 'ground_truth': 2, 'gpt_extracted': None, 'match': False}\n",
      "Trial 23: {'trial_number': 23, 'section': 'health_and_organ_function', 'key': 'creatinine_clearance_lower_bound', 'ground_truth': 60, 'gpt_extracted': None, 'match': False}\n",
      "Trial 23: {'trial_number': 23, 'section': 'health_and_organ_function', 'key': 'untreated_central_nervous_system_metastases', 'ground_truth': 'Not allowed', 'gpt_extracted': 'Allowed', 'match': False}\n",
      "\n",
      "Mismatch Count by Section and Key:\n",
      "Section: health_and_organ_function\n",
      "  untreated_central_nervous_system_metastases: 8 mismatches\n",
      "  anc_level_lower_bound_10_9_l: 3 mismatches\n",
      "  sufficient_lung_function: 2 mismatches\n",
      "  liver_function_bilirubin_upper_bound_uln: 6 mismatches\n",
      "  hgb_level_lower_bound_10_9_l: 4 mismatches\n",
      "  creatinine_clearance_lower_bound: 5 mismatches\n",
      "  ecog_performance_status_upper_bound: 5 mismatches\n",
      "  peripheral_neuropathy_grade_upper_bound: 6 mismatches\n",
      "  liver_function_ast_alt_upper_bound_uln: 4 mismatches\n",
      "  positive_hiv_status: 3 mismatches\n",
      "  creatinine_upper_bound_uln: 3 mismatches\n",
      "  plt_level_lower_bound_10_9_l: 3 mismatches\n",
      "  sufficient_renal_function: 2 mismatches\n",
      "  lvef_lower_bound_percent: 3 mismatches\n",
      "  karnofsky_performance_lower_bound: 2 mismatches\n",
      "  sufficient_bone_marrow: 1 mismatches\n",
      "  sufficient_liver_function: 1 mismatches\n",
      "  sufficient_heart_cardiovascular_function: 2 mismatches\n",
      "Section: disease_characteristics\n",
      "  disease_progression_after_previous_treatment: 2 mismatches\n",
      "  her2_status: 7 mismatches\n",
      "  er_pr_status: 4 mismatches\n",
      "  measurable_lesion: 4 mismatches\n",
      "  confirmed_metastases_breast_cancer: 6 mismatches\n",
      "  confirmed_breast_cancer: 2 mismatches\n",
      "Section: demographics_and_general_characteristics\n",
      "  months_of_life_expectancy: 4 mismatches\n",
      "  no_participation_in_other_clinical_trials: 3 mismatches\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def compare_extracted_criteria(gpt_data, ground_truth_data):\n",
    "    results = []\n",
    "    mismatch_counts = defaultdict(lambda: defaultdict(int))  # Track mismatches by section and key\n",
    "\n",
    "    for trial_index, (gpt_trial, gt_trial) in enumerate(zip(gpt_data, ground_truth_data), start=1):\n",
    "        gpt_criteria = gpt_trial.get(\"Extracted Criteria\", {})\n",
    "        gt_criteria = gt_trial.get(\"Extracted Criteria\", {})\n",
    "\n",
    "        for section in gpt_criteria:\n",
    "            # Skip specific sections\n",
    "            if section in [\"text_relating_to_medical_history\", \"unused_text\"]:\n",
    "                continue\n",
    "\n",
    "            gpt_section = gpt_criteria.get(section, {})\n",
    "            gt_section = gt_criteria.get(section, {})\n",
    "\n",
    "            for key, gt_value in gt_section.items():\n",
    "                gpt_value = gpt_section.get(key, None)\n",
    "                if (gpt_value in [\"Not required\", \"Both allowed\", \"Allowed\", 0] and not gt_value) or \\\n",
    "                   (gt_value in [\"Not required\", \"Both allowed\", \"Allowed\", 0] and not gpt_value):\n",
    "                    match = True\n",
    "                else:\n",
    "                    match = gt_value == gpt_value\n",
    "\n",
    "                results.append({\n",
    "                    \"trial_number\": trial_index,  # Add trial number\n",
    "                    \"section\": section,\n",
    "                    \"key\": key,\n",
    "                    \"ground_truth\": gt_value,\n",
    "                    \"gpt_extracted\": gpt_value,\n",
    "                    \"match\": match\n",
    "                })\n",
    "\n",
    "                # Increment mismatch count for the key in the section if there's a mismatch\n",
    "                if not match:\n",
    "                    mismatch_counts[section][key] += 1\n",
    "\n",
    "    return results, mismatch_counts\n",
    "\n",
    "\n",
    "def calculate_accuracy(results):\n",
    "    total = len(results)\n",
    "    matches = sum(1 for result in results if result[\"match\"])\n",
    "    return matches / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    gpt_file = \"extracted_criteria_30_new_merged.json\"\n",
    "    ground_truth_file = \"ground_truth_30.json\"\n",
    "\n",
    "    # Load data\n",
    "    gpt_data = load_json(gpt_file)\n",
    "    ground_truth_data = load_json(ground_truth_file)\n",
    "\n",
    "    # Compare criteria\n",
    "    comparison_results, mismatch_counts = compare_extracted_criteria(gpt_data, ground_truth_data)\n",
    "\n",
    "    accuracy = calculate_accuracy(comparison_results)\n",
    "    print(f\"Overall Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    mismatches = [r for r in comparison_results if not r[\"match\"]]\n",
    "    if mismatches:\n",
    "        print(\"\\nMismatched Entries:\")\n",
    "        for mismatch in mismatches:\n",
    "            print(f\"Trial {mismatch['trial_number']}: {mismatch}\")\n",
    "\n",
    "    print(\"\\nMismatch Count by Section and Key:\")\n",
    "    for section, keys in mismatch_counts.items():\n",
    "        print(f\"Section: {section}\")\n",
    "        for key, count in keys.items():\n",
    "            print(f\"  {key}: {count} mismatches\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aec50e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Results:\n",
      "Total Trials: 23\n",
      "Matched Trials: 7\n",
      "Overall Accuracy: 30.43%\n",
      "\n",
      "Sample Trial Results:\n",
      "\n",
      "Trial Text (first 100 chars): Inclusion Criteria:\n",
      "\n",
      "Patients with a history of histological and/or cytological proven HER2-positive...\n",
      "Match: True\n",
      "Accuracy: 100.0%\n",
      "\n",
      "Trial Text (first 100 chars): SELECTION OF PATIENTS (MOST IMPORTANT CRITERIA)\n",
      "\n",
      "Inclusion criteria for first-line therapy\n",
      "\n",
      "‚Ä¢ Hist...\n",
      "Match: False\n",
      "Accuracy: 100.0%\n",
      "Reason: Unknown mismatch\n",
      "Mismatches:\n",
      "- disease_characteristics.confirmed_locally_recurrent_breast_cancer\n",
      "- disease_characteristics.measurable_lesion\n",
      "\n",
      "Trial Text (first 100 chars): Inclusion Criteria:\n",
      "\n",
      "Histologically confirmed invasive cancer of the breast.\n",
      "Presence of at least on...\n",
      "Match: True\n",
      "Accuracy: 100.0%\n",
      "\n",
      "Trial Text (first 100 chars): Inclusion Criteria:\n",
      "\n",
      "Patients diagnosed with primary breast cancer attending hospital for the resect...\n",
      "Match: False\n",
      "Accuracy: 100.0%\n",
      "Reason: Unknown mismatch\n",
      "Mismatches:\n",
      "- demographics_and_general_characteristics\n",
      "\n",
      "Trial Text (first 100 chars): Inclusion Criteria:\n",
      "\n",
      "Histologically confirmed digestive or breast cancer that is metastatic or unres...\n",
      "Match: False\n",
      "Accuracy: 100.0%\n",
      "Reason: Unknown mismatch\n",
      "Mismatches:\n",
      "- health_and_organ_function.untreated_central_nervous_system_metastases\n",
      "- disease_characteristics.er_pr_status\n",
      "- disease_characteristics.her2_status\n",
      "\n",
      "Detailed results have been saved to 'comparison_results.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import difflib\n",
    "\n",
    "def normalize_value(value):\n",
    "    \"\"\"\n",
    "    Normalize values to make comparison more flexible\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    str_value = str(value).lower().strip()\n",
    "    \n",
    "    # Handle numeric values\n",
    "    if str_value.isdigit():\n",
    "        return int(str_value)\n",
    "    \n",
    "    # Normalize boolean-like values\n",
    "    if str_value in ['0', 'none', 'not allowed', 'not required', 'false']:\n",
    "        return 'not allowed'\n",
    "    \n",
    "    if str_value in ['1', 'required', 'allowed', 'true']:\n",
    "        return 'allowed'\n",
    "    \n",
    "    return str_value\n",
    "\n",
    "def filter_criteria(criteria):\n",
    "    \"\"\"\n",
    "    Remove 'text_relating_to_medical_history' and 'unused_text' from criteria\n",
    "    \"\"\"\n",
    "    if not isinstance(criteria, dict):\n",
    "        return criteria\n",
    "    \n",
    "    # Create a copy of the dictionary to avoid modifying the original\n",
    "    filtered = {}\n",
    "    for key, value in criteria.items():\n",
    "        if key not in ['text_relating_to_medical_history', 'unused_text']:\n",
    "            if isinstance(value, dict):\n",
    "                filtered[key] = filter_criteria(value)\n",
    "            else:\n",
    "                filtered[key] = value\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "def compare_extracted_criteria(ground_truth_data, extracted_data):\n",
    "    \"\"\"\n",
    "    Compare extracted criteria for each trial text\n",
    "    \"\"\"\n",
    "    # Create dictionaries keyed by trial text for easy matching\n",
    "    ground_truth_map = {\n",
    "        item.get('Trial Text', ''): filter_criteria(item.get('Extracted Criteria', {})) \n",
    "        for item in ground_truth_data\n",
    "    }\n",
    "    extracted_map = {\n",
    "        item.get('Trial Text', ''): filter_criteria(item.get('Extracted Criteria', {})) \n",
    "        for item in extracted_data\n",
    "    }\n",
    "    \n",
    "    # Tracking results\n",
    "    total_trials = 0\n",
    "    matched_trials = 0\n",
    "    trial_results = []\n",
    "    \n",
    "    # Compare each trial\n",
    "    for trial_text, ground_truth_criteria in ground_truth_map.items():\n",
    "        if not trial_text:\n",
    "            continue\n",
    "        \n",
    "        total_trials += 1\n",
    "        \n",
    "        # Find matching extracted criteria\n",
    "        extracted_criteria = extracted_map.get(trial_text, {})\n",
    "        \n",
    "        if not extracted_criteria:\n",
    "            trial_results.append({\n",
    "                'trial_text': trial_text,\n",
    "                'match': False,\n",
    "                'reason': 'No matching extracted criteria found'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Deep comparison of criteria\n",
    "        match_result = compare_criteria(ground_truth_criteria, extracted_criteria)\n",
    "        \n",
    "        trial_results.append({\n",
    "            'trial_text': trial_text,\n",
    "            'match': match_result['full_match'],\n",
    "            'accuracy': match_result['accuracy'],\n",
    "            'matches': match_result['matches'],\n",
    "            'mismatches': match_result['mismatches']\n",
    "        })\n",
    "        \n",
    "        if match_result['full_match']:\n",
    "            matched_trials += 1\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = (matched_trials / total_trials * 100) if total_trials > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_trials': total_trials,\n",
    "        'matched_trials': matched_trials,\n",
    "        'overall_accuracy': round(overall_accuracy, 2),\n",
    "        'trial_results': trial_results\n",
    "    }\n",
    "\n",
    "def compare_criteria(ground_truth, extracted):\n",
    "    \"\"\"\n",
    "    Compare individual criteria between ground truth and extracted data\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    mismatches = []\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    def recursive_compare(gt_dict, ext_dict, path=''):\n",
    "        nonlocal matches, mismatches, total_comparisons\n",
    "        \n",
    "        # Ensure both are dictionaries\n",
    "        if not isinstance(gt_dict, dict) or not isinstance(ext_dict, dict):\n",
    "            return\n",
    "        \n",
    "        # Compare keys\n",
    "        all_keys = set(list(gt_dict.keys()) + list(ext_dict.keys()))\n",
    "        \n",
    "        for key in all_keys:\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            \n",
    "            # Skip if key not in both dictionaries\n",
    "            if key not in gt_dict or key not in ext_dict:\n",
    "                mismatches.append(current_path)\n",
    "                continue\n",
    "            \n",
    "            # Get values\n",
    "            gt_value = gt_dict[key]\n",
    "            ext_value = ext_dict[key]\n",
    "            \n",
    "            # If nested dictionary, recurse\n",
    "            if isinstance(gt_value, dict) and isinstance(ext_value, dict):\n",
    "                recursive_compare(gt_value, ext_value, current_path)\n",
    "                continue\n",
    "            \n",
    "            # Normalize and compare values\n",
    "            total_comparisons += 1\n",
    "            norm_gt = normalize_value(gt_value)\n",
    "            norm_ext = normalize_value(ext_value)\n",
    "            \n",
    "            if norm_gt == norm_ext:\n",
    "                matches.append(current_path)\n",
    "            else:\n",
    "                mismatches.append(f\"{current_path}: GT={norm_gt}, Ext={norm_ext}\")\n",
    "    \n",
    "    # Perform recursive comparison\n",
    "    recursive_compare(ground_truth, extracted)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (len(matches) / total_comparisons * 100) if total_comparisons > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'full_match': len(mismatches) == 0,\n",
    "        'accuracy': round(accuracy, 2),\n",
    "        'matches': matches,\n",
    "        'mismatches': mismatches\n",
    "    }\n",
    "\n",
    "# Load ground truth and extracted data\n",
    "with open('ground_truth_30.json', 'r') as gt_file:\n",
    "    ground_truth_data = json.load(gt_file)\n",
    "\n",
    "with open('extracted_criteria_30_new_merged.json', 'r') as ext_file:\n",
    "    extracted_data = json.load(ext_file)\n",
    "\n",
    "# Run comparison\n",
    "comparison_results = compare_extracted_criteria(ground_truth_data, extracted_data)\n",
    "\n",
    "# Print detailed results\n",
    "print(\"Comparison Results:\")\n",
    "print(f\"Total Trials: {comparison_results['total_trials']}\")\n",
    "print(f\"Matched Trials: {comparison_results['matched_trials']}\")\n",
    "print(f\"Overall Accuracy: {comparison_results['overall_accuracy']}%\")\n",
    "\n",
    "# Print details of a few trials\n",
    "print(\"\\nSample Trial Results:\")\n",
    "for trial in comparison_results['trial_results'][:5]:\n",
    "    print(f\"\\nTrial Text (first 100 chars): {trial['trial_text'][:100]}...\")\n",
    "    print(f\"Match: {trial.get('match', 'N/A')}\")\n",
    "    print(f\"Accuracy: {trial.get('accuracy', 'N/A')}%\")\n",
    "    \n",
    "    if not trial.get('match', True):\n",
    "        print(\"Reason:\", trial.get('reason', 'Unknown mismatch'))\n",
    "    \n",
    "    # Print mismatches if available\n",
    "    if trial.get('mismatches'):\n",
    "        print(\"Mismatches:\")\n",
    "        for mismatch in trial['mismatches'][:5]:\n",
    "            print(f\"- {mismatch}\")\n",
    "\n",
    "# Optional: Write detailed results to a file\n",
    "with open('comparison_results.json', 'w') as results_file:\n",
    "    json.dump(comparison_results, results_file, indent=2)\n",
    "\n",
    "print(\"\\nDetailed results have been saved to 'comparison_results.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc2b1228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive Comparison Results:\n",
      "Total Parameters Compared: 327\n",
      "Total Correct Parameters: 321\n",
      "Overall Accuracy: 98.17%\n",
      "\n",
      "Top 10 Mismatches:\n",
      "Path: disease_characteristics.confirmed_locally_recurrent_breast_cancer, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "Path: disease_characteristics.measurable_lesion, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "Path: health_and_organ_function.untreated_central_nervous_system_metastases, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "Path: disease_characteristics.er_pr_status, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "Path: disease_characteristics.her2_status, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "Path: health_and_organ_function, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "Path: demographics_and_general_characteristics, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "Path: health_and_organ_function, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "Path: health_and_organ_function.untreated_central_nervous_system_metastases, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "Path: disease_characteristics.disease_progression_after_previous_treatment, Reason: Key missing in one of the dictionaries\n",
      "---\n",
      "\n",
      "Detailed results have been saved to 'comprehensive_comparison_results.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def normalize_value(value):\n",
    "    \"\"\"\n",
    "    Normalize values to make comparison more flexible\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    str_value = str(value).lower().strip()\n",
    "    \n",
    "    # Handle numeric values\n",
    "    if str_value.isdigit():\n",
    "        return int(str_value)\n",
    "    \n",
    "    # Normalize boolean-like values\n",
    "    if str_value in ['allowed', 'not required', 'both allowed']:\n",
    "        return 'allowed'\n",
    "    \n",
    "    if str_value in ['0']:\n",
    "        return ''\n",
    "    \n",
    "    return str_value\n",
    "\n",
    "def filter_criteria(criteria):\n",
    "    \"\"\"\n",
    "    Remove 'text_relating_to_medical_history' and 'unused_text' from criteria\n",
    "    \"\"\"\n",
    "    if not isinstance(criteria, dict):\n",
    "        return criteria\n",
    "    \n",
    "    # Create a copy of the dictionary to avoid modifying the original\n",
    "    filtered = {}\n",
    "    for key, value in criteria.items():\n",
    "        if key not in ['text_relating_to_medical_history', 'unused_text']:\n",
    "            if isinstance(value, dict):\n",
    "                filtered_nested = filter_criteria(value)\n",
    "                if filtered_nested:  # Only add if not empty\n",
    "                    filtered[key] = filtered_nested\n",
    "            else:\n",
    "                filtered[key] = value\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "def compare_criteria_detailed(ground_truth, extracted):\n",
    "    \"\"\"\n",
    "    Compare individual criteria between ground truth and extracted data\n",
    "    Provides detailed tracking of matches and mismatches\n",
    "    \"\"\"\n",
    "    total_comparisons = 0\n",
    "    correct_comparisons = 0\n",
    "    detailed_mismatches = []\n",
    "    \n",
    "    def recursive_compare(gt_dict, ext_dict, path=''):\n",
    "        nonlocal total_comparisons, correct_comparisons, detailed_mismatches\n",
    "        \n",
    "        # Ensure both are dictionaries\n",
    "        if not isinstance(gt_dict, dict) or not isinstance(ext_dict, dict):\n",
    "            return\n",
    "        \n",
    "        # Compare keys\n",
    "        all_keys = set(list(gt_dict.keys()) + list(ext_dict.keys()))\n",
    "        \n",
    "        for key in all_keys:\n",
    "            current_path = f\"{path}.{key}\" if path else key\n",
    "            \n",
    "            # Skip if key not in both dictionaries\n",
    "            if key not in gt_dict or key not in ext_dict:\n",
    "                detailed_mismatches.append({\n",
    "                    'path': current_path,\n",
    "                    'reason': 'Key missing in one of the dictionaries'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get values\n",
    "            gt_value = gt_dict[key]\n",
    "            ext_value = ext_dict[key]\n",
    "            \n",
    "            # If nested dictionary, recurse\n",
    "            if isinstance(gt_value, dict) and isinstance(ext_value, dict):\n",
    "                recursive_compare(gt_value, ext_value, current_path)\n",
    "                continue\n",
    "            \n",
    "            # Normalize and compare values\n",
    "            total_comparisons += 1\n",
    "            norm_gt = normalize_value(gt_value)\n",
    "            norm_ext = normalize_value(ext_value)\n",
    "            \n",
    "            if norm_gt == norm_ext:\n",
    "                correct_comparisons += 1\n",
    "            else:\n",
    "                detailed_mismatches.append({\n",
    "                    'path': current_path,\n",
    "                    'ground_truth': norm_gt,\n",
    "                    'extracted': norm_ext\n",
    "                })\n",
    "    \n",
    "    # Perform recursive comparison\n",
    "    recursive_compare(ground_truth, extracted)\n",
    "    \n",
    "    return {\n",
    "        'total_comparisons': total_comparisons,\n",
    "        'correct_comparisons': correct_comparisons,\n",
    "        'accuracy_percentage': (correct_comparisons / total_comparisons * 100) if total_comparisons > 0 else 0,\n",
    "        'detailed_mismatches': detailed_mismatches\n",
    "    }\n",
    "\n",
    "def comprehensive_comparison(ground_truth_data, extracted_data):\n",
    "    \"\"\"\n",
    "    Compare extracted criteria across all trials\n",
    "    \"\"\"\n",
    "    # Create dictionaries keyed by trial text for easy matching\n",
    "    ground_truth_map = {\n",
    "        item.get('Trial Text', ''): filter_criteria(item.get('Extracted Criteria', {})) \n",
    "        for item in ground_truth_data\n",
    "    }\n",
    "    extracted_map = {\n",
    "        item.get('Trial Text', ''): filter_criteria(item.get('Extracted Criteria', {})) \n",
    "        for item in extracted_data\n",
    "    }\n",
    "    \n",
    "    # Tracking overall results\n",
    "    overall_total_comparisons = 0\n",
    "    overall_correct_comparisons = 0\n",
    "    overall_detailed_mismatches = []\n",
    "    trial_results = []\n",
    "    \n",
    "    # Compare each trial\n",
    "    for trial_text, ground_truth_criteria in ground_truth_map.items():\n",
    "        if not trial_text:\n",
    "            continue\n",
    "        \n",
    "        # Find matching extracted criteria\n",
    "        extracted_criteria = extracted_map.get(trial_text, {})\n",
    "        \n",
    "        if not extracted_criteria:\n",
    "            continue\n",
    "        \n",
    "        # Detailed comparison for this trial\n",
    "        trial_comparison = compare_criteria_detailed(ground_truth_criteria, extracted_criteria)\n",
    "        \n",
    "        # Accumulate results\n",
    "        overall_total_comparisons += trial_comparison['total_comparisons']\n",
    "        overall_correct_comparisons += trial_comparison['correct_comparisons']\n",
    "        overall_detailed_mismatches.extend(trial_comparison['detailed_mismatches'])\n",
    "        \n",
    "        # Store trial-level results\n",
    "        trial_results.append({\n",
    "            'trial_text': trial_text,\n",
    "            'total_comparisons': trial_comparison['total_comparisons'],\n",
    "            'correct_comparisons': trial_comparison['correct_comparisons'],\n",
    "            'accuracy_percentage': trial_comparison['accuracy_percentage']\n",
    "        })\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = (overall_correct_comparisons / overall_total_comparisons * 100) if overall_total_comparisons > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_parameters_compared': overall_total_comparisons,\n",
    "        'total_correct_parameters': overall_correct_comparisons,\n",
    "        'overall_accuracy_percentage': round(overall_accuracy, 2),\n",
    "        'trial_results': trial_results,\n",
    "        'detailed_mismatches': overall_detailed_mismatches\n",
    "    }\n",
    "\n",
    "# Load ground truth and extracted data\n",
    "with open('ground_truth_30.json', 'r') as gt_file:\n",
    "    ground_truth_data = json.load(gt_file)\n",
    "\n",
    "with open('extracted_criteria_30_new_merged.json', 'r') as ext_file:\n",
    "    extracted_data = json.load(ext_file)\n",
    "\n",
    "# Run comprehensive comparison\n",
    "comparison_results = comprehensive_comparison(ground_truth_data, extracted_data)\n",
    "\n",
    "# Print detailed results\n",
    "print(\"Comprehensive Comparison Results:\")\n",
    "print(f\"Total Parameters Compared: {comparison_results['total_parameters_compared']}\")\n",
    "print(f\"Total Correct Parameters: {comparison_results['total_correct_parameters']}\")\n",
    "print(f\"Overall Accuracy: {comparison_results['overall_accuracy_percentage']}%\")\n",
    "\n",
    "# Print top mismatches\n",
    "print(\"\\nTop 10 Mismatches:\")\n",
    "top_mismatches = sorted(\n",
    "    comparison_results['detailed_mismatches'], \n",
    "    key=lambda x: 1 if 'ground_truth' in x else 0\n",
    ")[:10]\n",
    "for mismatch in top_mismatches:\n",
    "    if 'ground_truth' in mismatch:\n",
    "        print(f\"Path: {mismatch['path']}\")\n",
    "        print(f\"Ground Truth: {mismatch['ground_truth']}\")\n",
    "        print(f\"Extracted: {mismatch['extracted']}\")\n",
    "        print(\"---\")\n",
    "    else:\n",
    "        print(f\"Path: {mismatch['path']}, Reason: {mismatch['reason']}\")\n",
    "        print(\"---\")\n",
    "\n",
    "# Save detailed results\n",
    "with open('comprehensive_comparison_results.json', 'w') as results_file:\n",
    "    json.dump(comparison_results, results_file, indent=2)\n",
    "\n",
    "print(\"\\nDetailed results have been saved to 'comprehensive_comparison_results.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d66b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
